# Use Python 3.9 slim image
FROM python:3.9-slim

# Set the working directory inside the container
WORKDIR /app

# Install required system dependencies
RUN apt-get update && apt-get install -y \
    openjdk-11-jdk \
    wget \
    curl \
    unzip \
    git \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables for Java and Spark
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"

# Install Python dependencies
COPY requirements.txt .
RUN pip install --upgrade pip
RUN pip install -r requirements.txt

# Download and set up Apache Spark
ARG SPARK_VERSION=3.3.1
ARG HADOOP_VERSION=3
RUN wget -qO- "https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" | tar -xz -C /opt/
RUN mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark

# Install PySpark
RUN pip install pyspark==${SPARK_VERSION} findspark

# Expose ports for Spark UI and Jupyter Notebook
EXPOSE 4040 8888

# Copy project files into the container
COPY . .

# Start Jupyter Notebook by default
CMD ["jupyter", "notebook", "--ip", "0.0.0.0", "--port=8888", "--no-browser", "--allow-root"]